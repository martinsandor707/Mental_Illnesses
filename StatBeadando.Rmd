---
title: "Mental illnesses"
author: "Martin Sándor (F145XS)"
date: "2024-11-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Mentális betegségek elemzése
Az adatokat az [internetről szedtem le](https://www.kaggle.com/code/imtkaggleteam/mental-health-eda-prediction), fogalmam sincs, hogy valósak-e. Az oszlopokat átneveztem a könnyebb hivatkozás érdekében

## Az adatok megismerése

```{r}
illnesses <- read.csv('mental_illnesses.csv')
head(illnesses)
```


```{r}
usa_illnesses <- illnesses[illnesses["Code"] == "USA",]

#All disorders are represented as a % of the population
library(ggplot2)
ggplot(usa_illnesses, aes(x=Year, y=Depressive_disorders)) + geom_line(color="red4") + theme_minimal() + labs(title= "% of depressed population in the USA over time") + theme(plot.title = element_text(hjust=0.5, size=20, face="bold"))
```

Országonként nagy eltérések lehetnek az adatokban
```{r}
china_illnesses <- illnesses[illnesses["Code"] == "CHN",]
china_disorders <- china_illnesses[,4:ncol(china_illnesses)]

ggplot(china_illnesses, aes(x=Year, y=Depressive_disorders)) + geom_line(color="red4") + theme_minimal() + labs(title= "% of depressed population in China over time") + theme(plot.title = element_text(hjust=0.5, size=20, face="bold"))
```


```{r}
usa_disorders <- usa_illnesses[c("Schizophrenia", "Depressive_disorders", "Anxiety_disorders", "Bipolar_disorders", "Eating_disorders")]
head(usa_disorders)

```

```{r}
cor(usa_disorders)
```
A korreálciós mátrix alapján közepesen erős negatív korreálció van a skizofrénia és a depresszió között, míg a bipoláris zavar pozitív korrelációban áll a szorongással és az étkezési zavarokkal.

## Főkomponens analízis
```{r}
pcaUSA <- princomp(usa_disorders, cor = T)
summary(pcaUSA, loadings = T)
```
```{r}
screeplot(pcaUSA, col = 'blue', pch = 16, type = 'lines', cex = 2, lwd = 2, main = " ")
```

A módosított Kaiser szabály szerint csak a >=0.7 varianciájú komponenseket tartjuk meg, ebben az esetben az első kettőt. 

## Faktoranalízis

```{r}
eigen_values <- eigen(cor(usa_disorders))$values
scree_data <- data.frame(
  Factors = 1:length(eigen_values),
  Eigenvalues = eigen_values
)

ggplot(scree_data, aes(x = Factors, y = Eigenvalues)) +
  geom_point() +
  geom_line() +
  labs(title = "Scree Plot", x = "Factors", y = "Eigenvalues") +
  theme_minimal() +
  scale_x_continuous(breaks = 1:length(eigen_values)) +
  theme(axis.text.x = element_text(size = 12), 
        axis.text.y = element_text(size = 12), 
        title = element_text(size = 14))
```

Akkora faktorszámmal dolgozunk, amennyi sajátérték 1 fölött van az adathalmazon, ebben az esetben 2-vel

```{r}
fit <- factanal(usa_disorders, factors = 2, rotation="varimax")
print(fit)
```
Az eredmény nem túl meggyőző, a chi négyzet statisztika túl magas, és faktorszámban sem mehetünk feljebb. Emellett p értéke 0-közeli, így elutasítjuk a nullhipotézist, ami az lett volna, hogy a faktorok tökéletesen magyarázzák a paramétereket. Ezt az is megerősíti, hogy a két faktor kumulatív varianciája 0.66, tehát a kommunalitás csupán a variancia 2/3 részét magyarázza.

```{r}
usa_disorders$Code <- usa_illnesses$Code
china_disorders$Code <- china_illnesses$Code 

#Check normality
normality <- array(NA, dim = c(5))
normality[1] <- shapiro.test(usa_disorders$Schizophrenia)$p.value > 0.5
normality[2] <- shapiro.test(usa_disorders$Depressive_disorders)$p.value > 0.5
normality[3] <- shapiro.test(usa_disorders$Anxiety_disorders)$p.value > 0.5
normality[4] <- shapiro.test(usa_disorders$Bipolar_disorders)$p.value > 0.5
normality[5] <- shapiro.test(usa_disorders$Eating_disorders)$p.value > 0.5

normality
```
Az összes tulajdonság elbukott a shapiro-wilkins teszten, nem normális eloszlású az adat, így LDA, QDA kizárva. Logisztikus regressziót szintén nem használhatunk, mert nem elég nagy az adathalmaz, csupán 30-30 bejegyzés. Marad a klaszterezés.

## K-szomszéd klaszterezés

```{r}
library(caret)
library(class)
set.seed(123)

knn_illnesses <- rbind(usa_disorders, china_disorders)
knn_illnesses$Code <- factor(knn_illnesses$Code)
#Nem kéne hogy számítson, de a biztonság kedvéért megkeverem a sorokat
knn_illnesses <- knn_illnesses[sample(1:nrow(knn_illnesses)),]

#Klasszikus train/test split
train_index <- createDataPartition(knn_illnesses$Code, p = 0.7, list = FALSE)
train_data <- knn_illnesses[train_index,]
test_data <- knn_illnesses[-train_index,]

train_features <- train_data[, -ncol(train_data)]
train_labels <- train_data$Code
test_features <- test_data[, -ncol(test_data)]
test_labels <- test_data$Code

#Jellemzők standardizálása
train_features <- scale(train_features)
test_features <- scale(test_features)

k <- 2
knn_predictions <- knn(train = train_features, test = test_features, cl = train_labels, k = k)

# Pontosság kiszámítása
accuracy <- mean(knn_predictions == test_labels)
print(paste("Pontosság:", round(accuracy * 100, 2), "%"))

```

```{r}
#Konfúziós mátrix

confusionMatrix(knn_predictions, as.factor(test_labels))

```
Az amerikai és kínai adatokat látszólag tökéletesen sikerült elkülöníteni. Azonban ez várható volt, mert a két ország között hatalmas különbségek vannak.

Nézzük meg, hogy mi történik, ha szomszédos országokat próbálunk ugyanúgy klaszterezni! Ezúttal európai országokat veszünk alapul, és a változatosság kedvéért k-közép klaszterezést használunk k-szomszéd helyett. Így viszont a tanítás is felügyeletlen lesz.

## K-közép klaszterezés

```{r}
library(cluster)
#Új mintavétel
france_illnesses <- illnesses[illnesses["Code"] == "FRA",]
germany_illnesses <- illnesses[illnesses["Code"] == "DEU",]
britain_illnesses <- illnesses[illnesses["Code"] == "GBR",]

kmeans_illnesses <- rbind(france_illnesses, germany_illnesses,britain_illnesses)
kmeans_illnesses <- kmeans_illnesses[c(2,4:8)]
#Itt sem kéne számítania tbh, de jól esik a lelki világomnak lol
kmeans_illnesses <- kmeans_illnesses[sample(1:nrow(kmeans_illnesses)),]
kmeans_illnesses$Code <- factor(kmeans_illnesses$Code)

#Kihagyjuk a Code oszlopot
kmeans_result <- kmeans(kmeans_illnesses[,-1], centers=3, nstart=25)

kmeans_result
```

```{r}
confusion_matrix <- table(True_Label = kmeans_illnesses$Code, Cluster = kmeans_result$cluster)
print(confusion_matrix)
```

Úgy tűnik a szomszédság ellenére egyértelműen elválaszthatóak az értékek. (Ebből kiindulva valószínűleg nem valósak az adatok). Itt nem csináltam tanuló/tesztelő halmaz felbontást, mert felügyeletlen tanulásnál az a feltételezés hogy nincs mihez hasonlítani a jóságot, így a `kmeans` függvénynek sincs `test` paramétere.